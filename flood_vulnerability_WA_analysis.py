import os
import collections
import geopandas as gpd
import pandas as pd
import re

#Folder structure
rootdir = 'C:/Mathis/ICSL/flood_vulnerability'
datadir = os.path.join(rootdir, 'data')
resdir = os.path.join(rootdir, 'results')
gdb_vulne = os.path.join(resdir,'flood_vulnerability.gdb')
gdb = os.path.join(resdir,'flood_risk.gdb')

#Input data variables
tracts_proj = 'tracts_WAproj'
USadmin = 'C:\Mathis\ICSL\stormwater\data\USA_adm_gdb\USA_adm.gdb'
USstates = os.path.join(USadmin, 'USA_adm1')
counties = os.path.join(datadir,"WA_County_Boundaries\WA_County_Boundaries.shp")

parcels_flood_attri = gpd.read_file(gdb, layer='parcel_blocks_fill_snohflood_attri')
tracts_proj = gpd.read_file(gdb, layer='tracts_WAproj')
#Output variables

#--- Define functions
#Function to run weighted average on all numeric columns in a df
def weighed_average(grp, column): #From https://stackoverflow.com/questions/10951341/pandas-dataframe-aggregate-function-using-multiple-columns
    return(grp._get_numeric_data().multiply(grp[column], axis=0).sum())/grp[column].sum()

#----------------------------------- ANALYSIS ------------------------------------------
#Only keep parcels with positive population
pfa_sub = parcels_flood_attri[parcels_flood_attri['PARCELPOP']> 0]
#Compute "PARCELPOP"*"FloodStatus"
pfa_sub['floodpop'] = pfa_sub['PARCELPOP']*pfa_sub['FloodStatus']
#Compute population with predicted race/ethnicity
pfa_sub['census_pop'] = pfa_sub['pctwhite'].notnull()*pfa_sub['PARCELPOP']
pfa_sub['census_pop_flood'] = pfa_sub['pctwhite'].notnull()*pfa_sub['floodpop']
pfa_sub['lastpred_pop'] = pfa_sub['white'].notnull()*pfa_sub['PARCELPOP']
pfa_sub['lastpred_pop_flood'] = pfa_sub['white'].notnull()*pfa_sub['floodpop']
pfa_sub['lastfirstpred_pop'] = pfa_sub['nh_whitefl'].notnull()*pfa_sub['PARCELPOP']
pfa_sub['lastfirstpred_pop_flood'] = pfa_sub['nh_whitefl'].notnull()*pfa_sub['floodpop']

sumcols = ['TaxRollIDCount', 'HOUSINGADJ', 'PARCELPOP','TAXROLLNUM', 'BuildNum', 'BuildFld', 'FloodStatus', 'floodpop',
           'census_pop', 'census_pop_flood','lastpred_pop', 'lastpred_pop_flood', 'lastfirstpred_pop',
           'lastfirstpred_pop_flood', 'Shape_Area']
statdic = collections.OrderedDict()
for c in sumcols:
    statdic[c] = 'sum'
#Sum
t_ag1 = pfa_sub.groupby('GEOID10_t').agg(statdic)
t_ag1 = t_ag1.rename(index=str, columns={'Shape_Area':'ShArea_SUM'})

#Weighted average over all race columns based on population with predicted race/ethnicity for that model and flood population
census_cols = parcels_flood_attri.columns[18:24]
last_cols = parcels_flood_attri.columns[14:18] | parcels_flood_attri.columns[37:50]
lastfirst_cols = parcels_flood_attri.columns[24:37] | parcels_flood_attri.columns[50:54]

t_agcensus = pfa_sub[['GEOID10_t','census_pop']+list(census_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='census_pop').reset_index()
t_agcensus = t_agcensus.drop(columns=['census_pop'])

t_agcensus_flood = pfa_sub[['GEOID10_t','census_pop_flood']+list(census_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='census_pop_flood').reset_index()
t_agcensus_flood = t_agcensus_flood.drop(columns=['census_pop_flood'])
t_agcensus_flood.columns = [t_agcensus_flood.columns[0]]+[c+'_flood' for c in t_agcensus_flood.columns[1:]]

t_aglast = pfa_sub[['GEOID10_t','lastpred_pop']+list(last_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='lastpred_pop').reset_index()
t_aglast = t_aglast.drop(columns=['lastpred_pop'])

t_aglast_flood = pfa_sub[['GEOID10_t','lastpred_pop_flood']+list(last_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='lastpred_pop_flood').reset_index()
t_aglast_flood = t_aglast_flood.drop(columns=['lastpred_pop_flood'])
t_aglast_flood.columns = [t_agcensus_flood.columns[0]]+[c+'_flood' for c in t_aglast_flood.columns[1:]]

t_aglastfirst = pfa_sub[['GEOID10_t','lastfirstpred_pop']+list(lastfirst_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='lastfirstpred_pop').reset_index()
t_aglastfirst = t_aglastfirst.drop(columns=['lastfirstpred_pop'])

t_aglastfirst_flood = pfa_sub[['GEOID10_t','lastfirstpred_pop_flood']+list(lastfirst_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='lastfirstpred_pop_flood').reset_index()
t_aglastfirst_flood = t_aglastfirst_flood.drop(columns=['lastfirstpred_pop_flood'])
t_aglastfirst_flood.columns = [t_agcensus_flood.columns[0]]+[c+'_flood' for c in t_aglastfirst_flood.columns[1:]]

#Weighted average snohoperarea by AREA
t_agfloodarea = pfa_sub[['GEOID10_t','AREA']+['snohoperarea']].groupby('GEOID10_t')\
    .apply(weighed_average, column='AREA').reset_index()

#Merge all aggregated dfs
t_ag_dfs = [t_ag1, t_agcensus, t_agcensus_flood, t_aglast, t_aglast_flood, t_aglastfirst, t_aglastfirst_flood, t_agfloodarea]
t_ag_final = reduce(lambda left,right: pd.merge(left,right,on='GEOID10_t'), t_ag_dfs)

#Compute ratio of flood population and race/ethnicity statistics to general population and statistics
regx_flood = re.compile('[^a-b]flood', re.IGNORECASE)
for c in t_ag_final.columns:
    if regx_flood.search(c):
        c_base =  re.sub(regx_flood, '', c)
        if c_base in t_ag_final.columns:
            t_ag_final[c_base+'_ratio'] = (t_ag_final[c]-t_ag_final[c_base])/t_ag_final[c_base]

#-----------------------------  AGGREGATE RACE/ETHINICITY AT CENSUS TRACT LEVEL ----------------------------------------------
#Mere with census tract polygons
keepcols = ['GEOID10', 'Shape_Length', 'Shape_Area','geometry']
#Subset tract columns to include only data on race before exporting as .shp can only have 216 fields
regx_trace = re.compile('DP008|DP009|DP011', re.IGNORECASE)
racecols_t = []
for c in tracts_proj.columns:
    if regx_trace.match(c):
        racecols_t.append(c)
tract_attri = tracts_proj[keepcols+racecols_t].merge(t_ag_final, how='inner', left_on = 'GEOID10', right_on = 'GEOID10_t')
tract_attri['tp_arearatio'] = tract_attri['ShArea_SUM']/tract_attri['Shape_Area']
tract_attri['floodpop_ratio'] = tract_attri['floodpop']/tract_attri['PARCELPOP']
tract_attri.to_file(os.path.join(resdir,'tract_racefloodfinal.shp'))
import os
import collections
import geopandas as gpd
import pandas as pd

#Folder structure
rootdir = 'C:/Mathis/ICSL/flood_vulnerability'
datadir = os.path.join(rootdir, 'data')
resdir = os.path.join(rootdir, 'results')
gdb_vulne = os.path.join(resdir,'flood_vulnerability.gdb')
gdb = os.path.join(resdir,'flood_risk.gdb')

#Input data variables
tracts_proj = 'tracts_WAproj'
USadmin = 'C:\Mathis\ICSL\stormwater\data\USA_adm_gdb\USA_adm.gdb'
USstates = os.path.join(USadmin, 'USA_adm1')
counties = os.path.join(datadir,"WA_County_Boundaries\WA_County_Boundaries.shp")

#Output variables

#--- Define functions
#Function to run weighted average on all numeric columns in a df
def weighed_average(grp, column): #From https://stackoverflow.com/questions/10951341/pandas-dataframe-aggregate-function-using-multiple-columns
    return (grp._get_numeric_data().multiply(grp[column], axis=0).sum())/grp[column].sum()

#----------------------------------- ANALYSIS ------------------------------------------
parcels_flood_attri = gpd.read_file(gdb, layer='parcel_blocks_fill_snohflood_attri')
#Only keep parcels with positive population
pfa_sub = parcels_flood_attri[parcels_flood_attri['PARCELPOP']> 0]
#Compute "PARCELPOP"*"FloodStatus"
pfa_sub['floodpop'] = pfa_sub['PARCELPOP']*pfa_sub['FloodStatus']
#Compute population with predicted race/ethnicity
pfa_sub['census_pop'] = pfa_sub['pctwhite'].notnull()*pfa_sub['PARCELPOP']
pfa_sub['census_floodpop'] = pfa_sub['pctwhite'].notnull()*pfa_sub['floodpop']
pfa_sub['lastpred_pop'] = pfa_sub['white'].notnull()*pfa_sub['PARCELPOP']
pfa_sub['lastpred_floodpop'] = pfa_sub['white'].notnull()*pfa_sub['floodpop']
pfa_sub['lastfirstpred_pop'] = pfa_sub['nh_whitefl'].notnull()*pfa_sub['PARCELPOP']
pfa_sub['lastfirstpred_floodpop'] = pfa_sub['nh_whitefl'].notnull()*pfa_sub['floodpop']

sumcols = ['TaxRollIDCount', 'HOUSINGADJ', 'PARCELPOP','TAXROLLNUM', 'BuildNum', 'BuildFld', 'FloodStatus',
           'census_pop', 'lastpred_pop', 'lastfirstpred_pop']
statdic = collections.OrderedDict()
for c in sumcols:
    statdic[c] = 'sum'
#Sum
t_ag1 = pfa_sub.groupby('GEOID10_t').agg(statdic)

#Weighted average over all race columns based on population with predicted race/ethnicity for that model and flood population
census_cols = parcels_flood_attri.columns[18:24]
last_cols = parcels_flood_attri.columns[14:18] | parcels_flood_attri.columns[37:50]
lastfirst_cols = parcels_flood_attri.columns[24:37] | parcels_flood_attri.columns[50:54]

t_agcensus = pfa_sub[['GEOID10_t','census_pop']+list(census_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='census_pop')
t_agcensus_flood = pfa_sub[['GEOID10_t','census_floodpop']+list(census_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='census_floodpop')
t_aglast = pfa_sub[['GEOID10_t','lastpred_pop']+list(last_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='lastpred_pop')
t_aglast_flood = pfa_sub[['GEOID10_t','lastpred_floodpop']+list(last_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='lastpred_floodpop')
t_aglastfirst = pfa_sub[['GEOID10_t','lastfirstpred_pop']+list(lastfirst_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='lastfirstpred_pop')
t_aglastfirst_flood = pfa_sub[['GEOID10_t','lastfirstpred_floodpop']+list(lastfirst_cols)].groupby('GEOID10_t').\
    apply(weighed_average, column='lastfirstpred_floodpop')

#Weighted average snohoperarea by AREA
t_agfloodarea = pfa_sub[['GEOID10_t','AREA']+['snohoperarea']].groupby('GEOID10_t').apply(weighed_average, column='AREA')
t_ag_dfs = [t_ag1, t_agcensus, t_agcensus_flood, t_aglast, t_aglast_flood, t_aglastfirst, t_aglastfirst_flood, t_agfloodarea]
for df in t_ag_dfs:
    df.reset_index(inplace=True)
t_ag_final = reduce(lambda left,right: pd.merge(left,right,on='GEOID10_t'), t_ag_dfs)



#-----------------------------  AGGREGATE RACE/ETHINICITY AT CENSUS TRACT LEVEL ----------------------------------------------














t_ag1.columns = ['_'.join(col).strip() for col in t_ag1.columns.values]
#Run average on all race columns aside from those generated by census database model (as many more NaN in that one)
t_ag2 = merge2_sub2[['GEOID10_t','PARCELPOP']+list(sub2_meancols)].groupby('GEOID10_t').apply(weighed_average)
#Run average on all base census model race columns
t_ag3 = merge2_sub3[['GEOID10_t','PARCELPOP']+list(rdf_ln2010.columns[6:])].groupby('GEOID10_t').apply(weighed_average)

t_ag4 = t_ag1.merge(t_ag2, how='outer', on = 'GEOID10_t') #Merge two summary stat df
t_ag = t_ag4.merge(t_ag3, how='outer', on = 'GEOID10_t')
t_ag.reset_index(inplace=True)
t_ag = t_ag.drop(columns=['PARCELPOP_x', 'PARCELPOP_y'])

#Subset tract columns to include only data on race before exporting as .shp can only have 216 fields
regx_trace = re.compile('DP008|DP009|DP011', re.IGNORECASE)
racecols_t = []
for c in tract.columns:
    if regx_trace.match(c):
        racecols_t.append(c)
tract_attri = tract[keepcols+racecols_t].merge(t_ag, how='outer', left_on = 'GEOID10', right_on = 'GEOID10_t')
tract_attri.to_file('tract_racepred.shp')

import arcpy
import os
import sys
import re
from collections import defaultdict

arcpy.CheckOutExtension("Spatial")
arcpy.env.overwriteOutput = True
arcpy.env.qualifiedFieldNames = False

#Folder structure
rootdir = 'C:/Mathis/ICSL/flood_vulnerability'
datadir = os.path.join(rootdir, 'data')
resdir = os.path.join(rootdir, 'results')
gdb_vulne = os.path.join(resdir,'flood_vulnerability.gdb')

gdb = os.path.join(resdir,'flood_risk.gdb')
if arcpy.Exists(gdb):
    print('Geodatabase already exists')
else:
    arcpy.CreateFileGDB_management(resdir, 'flood_risk.gdb')
arcpy.env.workspace = gdb

WAdb = os.path.join(datadir, 'WAParcel\StatewideParcels_v2012_e9.2_r1.3\StatewideParcels_v2012_e9.2_r1.3.gdb')#Washington statewide parcel database
parcel = os.path.join(WAdb, 'Land\Parcel')
parcel_name = os.path.join(WAdb, 'Name')
parcel_taxroll = os.path.join(WAdb, 'TaxRoll')
parcel_taxrollname_r = os.path.join(WAdb, 'TaxRollsHaveNames')
StateLU =  os.path.join(WAdb, 'StateLandUse')
provider = os.path.join(WAdb, 'DataProvider')

#Output variables
parcel_nogeodupli = 'parcel_o5county_nogeodupli'
taxroll_nogeodupli = 'taxroll_nogeodupli'

#-----------------------------------------------------------------------------------------------------------------------
# CLEAN PARCEL DATASET
#-----------------------------------------------------------------------------------------------------------------------
#Remove parcels < 5m2 - cannot hold any housing, often slivers due to polygon processing
arcpy.AddGeometryAttributes_management(parcel, 'AREA', Area_Unit='SQUARE_METERS')
arcpy.MakeFeatureLayer_management(parcel, 'parcel_lyr', '"POLY_AREA">5')
arcpy.CopyFeatures_management('parcel_lyr', 'parcel_o5')

#Separate county data from other state and federal data
#Create list of data providers code
providerID = {}
for row in arcpy.da.SearchCursor(provider, ['DataProviderID','Name']):
    providerID[row[0]] = row[1]
#DNR: 640, WDFW: 641, BLM: 843
arcpy.MakeFeatureLayer_management('parcel_o5', 'parcel_o5lyr', 'NOT "DataProviderID" IN {}'.format(str(tuple([640,641,843]))))
arcpy.CopyFeatures_management('parcel_o5lyr', 'parcel_o5county')

#Check for polygons with duplicate geometry
arcpy.FindIdentical_management('parcel_o5county', 'parcel_o5county_geodupli', fields='Shape', output_record_option='ONLY_DUPLICATES')
arcpy.MakeFeatureLayer_management('parcel_o5county', 'parcel_o5county_lyr')
arcpy.AddJoin_management('parcel_o5county_lyr', 'OBJECTID', 'parcel_o5county_geodupli', 'IN_FID', join_type='KEEP_COMMON')
arcpy.CopyFeatures_management('parcel_o5county_lyr', 'parcel_o5county_geoduplipoly')

arcpy.MakeTableView_management(parcel_taxroll, 'taxroll_view')
arcpy.AddJoin_management('taxroll_view','PolyID','parcel_o5county_geoduplipoly','PolyID', join_type='KEEP_COMMON')
arcpy.CopyRows_management('taxroll_view', 'taxroll_parcel_o5county_geoduplipoly')

#------------------------- Deal with duplicate polygon geometries ------------------------------------------------------
#Check https://depts.washington.edu/wagis/projects/parcels/techdocs/ for more info on removing and flattening records
#Make copy of parcel_o5county
arcpy.CopyFeatures_management('parcel_o5county', parcel_nogeodupli)
#Add Field: ProcessParcelFlattened_MM
arcpy.AddField_management(parcel_nogeodupli , 'ProcessParcelFlattened_MM', field_type='SHORT')
arcpy.CalculateField_management(parcel_nogeodupli, 'ProcessParcelFlattened_MM',
                                expression='!ProcessParcelFlattened!', expression_type='PYTHON')
#Add Field: ProcessParcelDuplicatesRemoved_MM
arcpy.AddField_management(parcel_nogeodupli , 'ProcessParcelDuplicatesRemoved_MM', field_type='SHORT')
arcpy.CalculateField_management(parcel_nogeodupli, 'ProcessParcelDuplicatesRemoved_MM',
                                expression='!ProcessParcelDuplicatesRemoved!', expression_type='PYTHON')
#Prepare dics for removal and flattening
polyflatten = defaultdict(list)
polyremove = defaultdict(list)
polykeep = defaultdict(list)
#Define fields to check for identifying identical records
regx_fields = re.compile('|'.join(['PolyID.*', 'TaxRollID.*', 'TaxAccountID.*', 'SourceParcelID.*', 'OBJECTID.*',
                                   'IN_FID.*','POLY_AREA.*','SHAPE_Length.*','SHAPE_Area.*','ProcessParcelDuplicatesRemoved',
                                   'GISAcres']))
checkidentical_fields = [f.name for f in arcpy.ListFields('taxroll_parcel_o5county_geoduplipoly') if not regx_fields.search(f.name)]

duplipoly_fields = ['PolyID','FEAT_SEQ','ProcessParcelFlattened','ProcessParcelDuplicatesRemoved']
fieldlim = len(duplipoly_fields)
with arcpy.da.SearchCursor('taxroll_parcel_o5county_geoduplipoly', duplipoly_fields+checkidentical_fields) as cursor:
    for row in cursor:
        print(row)
        if row[1] not in polykeep: #If FEAT_SEQ not already in polykeep dic
            polykeep[row[1]] = list(row) #Add to polykeep
        else:
            if polykeep[row[1]][fieldlim:]==list(row[fieldlim:]): #If identical records in substance
                if polykeep[row[1]][0] != row[0]:
                    print('Identical!')
                    # Based on PolyID, add ProcessParcelDuplicatesRemoved + PolyID of the polygon to keep to polyremove dic
                    polyremove[row[0]]=[row[3],polykeep[row[1]][0]]
            else:
                if polykeep[row[1]][0] != row[0]: #If different PolyID
                    if polykeep[row[1]][2] <= row[2]:  #If ProcessParcelFlattened > that in dictionary
                        polyflatten[row[0]] = [polykeep[row[1]][2], row[0]]  #Add that in polykeep to polyflatten
                        polykeep[row[1]] = list(row) #Add current one to polyflatten
                    else:
                        polyflatten[row[0]]= [row[2],polykeep[row[1]][0]] #Add to polyflatten

#Delete duplicated polygons in parcel dataset
parcelclean_fields = ['PolyID','ProcessParcelFlattened_MM','ProcessParcelDuplicatesRemoved_MM']
with arcpy.da.UpdateCursor(parcel_nogeodupli, parcelclean_fields) as cursor:
    for row in cursor:
        try:
            #INCREMENTING FLATTEN COUNT
            if row[0] in [v[1] for v in polyflatten.values() if len(v) > 1]:  # if poly associated with a flattened polygon, increment ProcessParcelFlattened_MM
                print('Increment flatten count' + str(row[0]))
                flattencount_prior = [v[0] for v in polyflatten.values() if len(v) > 1 and row[0] == v[1]][0]
                if row[1] is None:
                    row[1] = 1
                if flattencount_prior is None:  # Add 1 if no previously flattened polygon
                    row[1] = row[1] + 1
                else:
                    row[1] = row[1] + flattencount_prior
                cursor.updateRow(row)
            #INCREMENTING REMOVAL COUNT
            if row[0] in [v[1] for v in polyremove.values() if len(v)>1]: #if poly associated with a removed polygon, increment ProcessParcelDuplicatesRemoved_MM
                print('Increment remove count' + str(row[0]))
                removecount_prior = [v[0] for v in polyremove.values() if len(v) > 1 and row[0] == v[1]][0]
                if row[2] is None:
                    row[2]=1
                if removecount_prior is None: #Add 1 if no removed polygons previously associated with deleted polygon
                    row[2]=row[2]+1
                else:
                    row[2]=row[2]+removecount_prior
                cursor.updateRow(row)
            #DELETE ROW IF IN REMOVE DIC
            if row[0] in polyremove or row[0] in polyflatten: #if PolyID in remove or flatten dictionary
                print('Delete'+str(row[0]))
                cursor.deleteRow() #Delete polygon
        except:
            print(row[0])
            e = sys.exc_info()[1]
            print(e.args[0])
del row
del cursor

#Edit Taxroll records to point taxroll to correct polygon (as some duplicated polygons were deleted)
arcpy.CopyRows_management(parcel_taxroll, taxroll_nogeodupli)
with arcpy.da.UpdateCursor(taxroll_nogeodupli, ['PolyID']) as cursor:
    print(row[0])
    if row[0] in polyflatten: #If row was deleted because identical poly geometry but different taxroll data, then
        row[0]=polyflatten[row[0]][1]  #Change PolyID in taxroll record to refer to the remaining (unique) polygon
        cursor.updateRow(row)
    if row[0] in polyremove: #If row was deleted because poly geometry and taxroll record was identical, then
        cursor.deleteRow() #Delete TaxRoll record as identical
del row
del cursor

#------------------------- Deal with intersecting polygons ------------------------------------------------------



##################INSPECT DUPLICATE POLYID IN TAXROLL############
#Often, when a parcel contains multiple sub-properties (e.g. condo building contains multiple condos), then a single
#POLYID (parcel) may be associated with multiple TaxRollID (units that could be paid taxes one).
#However, there can't be several NameID per TaxRollID and some duplicate POLYID are erroneous

# Check for ProcessParcelFlattened

#Check which of:
    #TabularAcre of each individual record or sum of all records best matches polygon area
#If no tabular acres and single family:
    # check highest total value (in order): TaxableValueTotal, TaxableValueImprovements+TaxableValueLand, MarketValueTotal,
    #    MarketValueImprovements, MarketValueLand
    # check whether tabular acre even remotely close to POLY_AREA

#If other than single family:
    #Check if # in ProcessParcelFlattened+1 matches number of records

#-----------------------------------------------------------------------------------------------------------------------
# DOWNSCALE CENSUS
#-----------------------------------------------------------------------------------------------------------------------
#---------------Method 1: downscale census block population based on parcel area----------------------------------------
#Intersect parcel with census block population

#---------------Method 2: downscale census block population based on impervious area within parcel----------------------
    #Get US NAIP land cover data
    #With impervious area
    #Without impervious area: lower 10th percentile of block of same size?

#---------------Method 3: downscale census block population based on parcel information---------------------------------
    #When duplicate PolyID, add number of duplicates as usually due to e.g. multiple condos within condo unit
    #Get number of units from LanduSeCD
    #Get unit size from Improvement?
    #Get number of rooms from Improvement?
    #Get construction year + renovation year

    #Residential areas without unit size or number of rooms







#Join taxroll attributes to parcel polygons (one-to-many relationship from parcel to taxrollIDs so require query
arcpy.MakeFeatureLayer_management(parcel, 'parcel_lyr')
try:
    SQLjoin = 'Parcel.PolyID = TaxRoll.PolyID'
    # Make Query Table...
    arcpy.MakeQueryTable_management([parcel, parcel_taxroll], 'parcel_taxroll_query', "ADD_VIRTUAL_KEY_FIELD", where_clause=SQLjoin)
except Exception as err:
    print(err.args[0])
arcpy.CopyFeatures_management('parcel_taxroll_query', 'parcel_taxroll')
import arcpy
import os
import sys
import re
from collections import defaultdict

arcpy.CheckOutExtension("Spatial")
arcpy.env.overwriteOutput = True
arcpy.env.qualifiedFieldNames = False

#Folder structure
rootdir = 'C:/Mathis/ICSL/flood_vulnerability'
datadir = os.path.join(rootdir, 'data')
resdir = os.path.join(rootdir, 'results')
gdb_vulne = os.path.join(resdir,'flood_vulnerability.gdb')

gdb = os.path.join(resdir,'flood_risk.gdb')
if arcpy.Exists(gdb):
    print('Geodatabase already exists')
else:
    arcpy.CreateFileGDB_management(resdir, 'flood_risk.gdb')
arcpy.env.workspace = gdb

counties = os.path.join(datadir,"WA_County_Boundaries\WA_County_Boundaries.shp")

WAdb = os.path.join(datadir, 'WAParcel\StatewideParcels_v2012_e9.2_r1.3\StatewideParcels_v2012_e9.2_r1.3.gdb')#Washington statewide parcel database
parcel = os.path.join(WAdb, 'Land\Parcel')
parcel_name = os.path.join(WAdb, 'Name')
parcel_taxroll = os.path.join(WAdb, 'TaxRoll')
parcel_taxrollname_r = os.path.join(WAdb, 'TaxRollsHaveNames')
StateLU =  os.path.join(WAdb, 'StateLandUse')
provider = os.path.join(WAdb, 'DataProvider')

#Output variables
parcel_nogeodupli = 'parcel_o5county_nogeodupli'
taxroll_nogeodupli = 'taxroll_nogeodupli'

#-----------------------------------------------------------------------------------------------------------------------
# CLEAN PARCEL DATASET
#-----------------------------------------------------------------------------------------------------------------------
#Remove parcels < 5m2 - cannot hold any housing, often slivers due to polygon processing
arcpy.AddGeometryAttributes_management(parcel, 'AREA', Area_Unit='SQUARE_METERS')
arcpy.MakeFeatureLayer_management(parcel, 'parcel_lyr', '"POLY_AREA">5')
arcpy.CopyFeatures_management('parcel_lyr', 'parcel_o5')

#Separate county data from other state and federal data
#Create list of data providers code
providerID = {}
for row in arcpy.da.SearchCursor(provider, ['DataProviderID','Name']):
    providerID[row[0]] = row[1]
#DNR: 640, WDFW: 641, BLM: 843
arcpy.MakeFeatureLayer_management('parcel_o5', 'parcel_o5lyr', 'NOT "DataProviderID" IN {}'.format(str(tuple([640,641,843]))))
arcpy.CopyFeatures_management('parcel_o5lyr', 'parcel_o5county')

#Check for polygons with duplicate geometry
arcpy.FindIdentical_management('parcel_o5county', 'parcel_o5county_geodupli', fields='Shape', output_record_option='ONLY_DUPLICATES')
arcpy.MakeFeatureLayer_management('parcel_o5county', 'parcel_o5county_lyr')
arcpy.AddJoin_management('parcel_o5county_lyr', 'OBJECTID', 'parcel_o5county_geodupli', 'IN_FID', join_type='KEEP_COMMON')
arcpy.CopyFeatures_management('parcel_o5county_lyr', 'parcel_o5county_geoduplipoly')

arcpy.MakeTableView_management(parcel_taxroll, 'taxroll_view')
arcpy.AddJoin_management('taxroll_view','PolyID','parcel_o5county_geoduplipoly','PolyID', join_type='KEEP_COMMON')
arcpy.CopyRows_management('taxroll_view', 'taxroll_parcel_o5county_geoduplipoly')

#------------------------- Deal with duplicate polygon geometries ------------------------------------------------------
#Check https://depts.washington.edu/wagis/projects/parcels/techdocs/ for more info on removing and flattening records
#Make copy of parcel_o5county
arcpy.CopyFeatures_management('parcel_o5county', parcel_nogeodupli)
#Add Field: ProcessParcelFlattened_MM
arcpy.AddField_management(parcel_nogeodupli , 'ProcessParcelFlattened_MM', field_type='SHORT')
arcpy.CalculateField_management(parcel_nogeodupli, 'ProcessParcelFlattened_MM',
                                expression='!ProcessParcelFlattened!', expression_type='PYTHON')
#Add Field: ProcessParcelDuplicatesRemoved_MM
arcpy.AddField_management(parcel_nogeodupli , 'ProcessParcelDuplicatesRemoved_MM', field_type='SHORT')
arcpy.CalculateField_management(parcel_nogeodupli, 'ProcessParcelDuplicatesRemoved_MM',
                                expression='!ProcessParcelDuplicatesRemoved!', expression_type='PYTHON')
#Prepare dics for removal and flattening
polyflatten = defaultdict(list)
polyremove = defaultdict(list)
polykeep = defaultdict(list)
#Define fields to check for identifying identical records
regx_fields = re.compile('|'.join(['PolyID.*', 'TaxRollID.*', 'TaxAccountID.*', 'SourceParcelID.*', 'OBJECTID.*',
                                   'IN_FID.*','POLY_AREA.*','SHAPE_Length.*','SHAPE_Area.*','ProcessParcelDuplicatesRemoved',
                                   'GISAcres']))
checkidentical_fields = [f.name for f in arcpy.ListFields('taxroll_parcel_o5county_geoduplipoly') if not regx_fields.search(f.name)]

duplipoly_fields = ['PolyID','FEAT_SEQ','ProcessParcelFlattened','ProcessParcelDuplicatesRemoved']
fieldlim = len(duplipoly_fields)
with arcpy.da.SearchCursor('taxroll_parcel_o5county_geoduplipoly', duplipoly_fields+checkidentical_fields) as cursor:
    for row in cursor:
        print(row)
        if row[1] not in polykeep: #If FEAT_SEQ not already in polykeep dic
            polykeep[row[1]] = list(row) #Add to polykeep
        else:
            if polykeep[row[1]][fieldlim:]==list(row[fieldlim:]): #If identical records in substance
                if polykeep[row[1]][0] != row[0]:
                    print('Identical!')
                    # Based on PolyID, add ProcessParcelDuplicatesRemoved + PolyID of the polygon to keep to polyremove dic
                    polyremove[row[0]]=[row[3],polykeep[row[1]][0]]
            else:
                if polykeep[row[1]][0] != row[0]: #If different PolyID
                    if polykeep[row[1]][2] <= row[2]:  #If ProcessParcelFlattened > that in dictionary
                        polyflatten[row[0]] = [polykeep[row[1]][2], row[0]]  #Add that in polykeep to polyflatten
                        polykeep[row[1]] = list(row) #Add current one to polyflatten
                    else:
                        polyflatten[row[0]]= [row[2],polykeep[row[1]][0]] #Add to polyflatten

#Delete duplicated polygons in parcel dataset
parcelclean_fields = ['PolyID','ProcessParcelFlattened_MM','ProcessParcelDuplicatesRemoved_MM']
with arcpy.da.UpdateCursor(parcel_nogeodupli, parcelclean_fields) as cursor:
    for row in cursor:
        try:
            #INCREMENTING FLATTEN COUNT
            if row[0] in [v[1] for v in polyflatten.values() if len(v) > 1]:  # if poly associated with a flattened polygon, increment ProcessParcelFlattened_MM
                print('Increment flatten count' + str(row[0]))
                flattencount_prior = [v[0] for v in polyflatten.values() if len(v) > 1 and row[0] == v[1]][0]
                if row[1] is None:
                    row[1] = 1
                if flattencount_prior is None:  # Add 1 if no previously flattened polygon
                    row[1] = row[1] + 1
                else:
                    row[1] = row[1] + flattencount_prior
                cursor.updateRow(row)
            #INCREMENTING REMOVAL COUNT
            if row[0] in [v[1] for v in polyremove.values() if len(v)>1]: #if poly associated with a removed polygon, increment ProcessParcelDuplicatesRemoved_MM
                print('Increment remove count' + str(row[0]))
                removecount_prior = [v[0] for v in polyremove.values() if len(v) > 1 and row[0] == v[1]][0]
                if row[2] is None:
                    row[2]=1
                if removecount_prior is None: #Add 1 if no removed polygons previously associated with deleted polygon
                    row[2]=row[2]+1
                else:
                    row[2]=row[2]+removecount_prior
                cursor.updateRow(row)
            #DELETE ROW IF IN REMOVE DIC
            if row[0] in polyremove or row[0] in polyflatten: #if PolyID in remove or flatten dictionary
                print('Delete'+str(row[0]))
                cursor.deleteRow() #Delete polygon
        except:
            print(row[0])
            e = sys.exc_info()[1]
            print(e.args[0])
del row
del cursor

#Edit Taxroll records to point taxroll to correct polygon (as some duplicated polygons were deleted)
arcpy.CopyRows_management(parcel_taxroll, taxroll_nogeodupli)
with arcpy.da.UpdateCursor(taxroll_nogeodupli, ['PolyID']) as cursor:
    print(row[0])
    if row[0] in polyflatten: #If row was deleted because identical poly geometry but different taxroll data, then
        row[0]=polyflatten[row[0]][1]  #Change PolyID in taxroll record to refer to the remaining (unique) polygon
        cursor.updateRow(row)
    if row[0] in polyremove: #If row was deleted because poly geometry and taxroll record was identical, then
        cursor.deleteRow() #Delete TaxRoll record as identical
del row
del cursor

#------------------------- Check and deal with intersecting polygons ---------------------------------------------------
#Run test solve on Columbia County Area
arcpy.MakeFeatureLayer_management('parcel_o5county', 'parcel_o5ColumbiaCounty', where_clause='"DataProviderID"=407')
#Create identical copy of dataset to intersect
arcpy.CopyFeatures_management('parcel_o5ColumbiaCounty', 'parcel_o5columbia')
#Self intersect parcel dataset to know what parcel overlaps which other one
co_inters = 'parcel_o5columbia_inters'
arcpy.Intersect_analysis(['parcel_o5columbia', 'parcel_o5county'], co_inters)
#Only keep intersections resulting from overlap between two separate parcels
[f.name for f in arcpy.ListFields(co_inters)]
co_sub = co_inters+'sub'
arcpy.MakeFeatureLayer_management(co_inters, co_sub+'lyr', where_clause='NOT "PolyID"="PolyID_1"')
arcpy.CopyFeatures_management(co_sub+'lyr',co_sub)
#Spatial join with WA counties to know which parcels are completely within a county and which
co_join = co_sub+'_join'
arcpy.SpatialJoin_analysis(co_sub, counties, co_join, join_operation='JOIN_ONE_TO_ONE', match_option='COMPLETELY_WITHIN')
#Deal with duplicate geometries:
# For each polygon, compute percentage overlap in area (with POLY_AREA)
# Compute first one of all those that overlap > 99%






# Deal with slivers: try and find a way to use 'eliminate' in ArcGIS
# Deal with overlap between counties: if polygon is fully contained within a county, then only keep the polygon for that county.
#   Otherwise, pick a drawing order for counties and consistently eliminate overlapping area from the country that is
#   lower on the list based on that
# Deal with enveloped polygons: identify polygons completely contained within another one and at least < 75% of the size
#   of the bigger one. Erase the part of the bigger polygon that overlaps the smaller one.
# For big messes like Whitman County: just create a uniform layer trying to keep the largest polygons.





"""Observed patterns of parcel overlaps:
1. Slivers created along edges of polygons. Not a problem. Can delete overlap if small. 
2. Whitman County overall is a mess, all polygons are overlapping in potentially meaningless ways. 
Not sure that it is usable?
3. Multiple polygons are embedded within a larger one (e.g. paper product factor within a lumber yard, individual
mobile homes within a mobile home park). Can identify those polygons fully contained within another and erasing enveloping
polygon from the smaller polygon's footprint. 
4. Duplicate polygons over county boundaries. In this case, 
5. A a lot of duplicate geometries still where two polygons are visibly identical and fully overlap, yet not 100% so were
not identified by FindIdentical on !SHAPE!. Is there a need to relax the tolerance of the Find Identical tool? 
    - Test multiple tolerance threshold in FindIdentical on an area with a lot of overlapping duplicates of Columbia County: 
    Try 1,2, 5, 10, 25 m. Even at 25 m, still not great. Not going to work.
    - Identify those polygons that overlap for more than 99% of each other's surface area? See how that goes. Otherwise,
    can try a centroid+perimeter+area check.  
"""


##################INSPECT DUPLICATE POLYID IN TAXROLL############
#Often, when a parcel contains multiple sub-properties (e.g. condo building contains multiple condos), then a single
#POLYID (parcel) may be associated with multiple TaxRollID (units that could be paid taxes one).
#However, there can't be several NameID per TaxRollID and some duplicate POLYID are erroneous

# Check for ProcessParcelFlattened

#Check which of:
    #TabularAcre of each individual record or sum of all records best matches polygon area
#If no tabular acres and single family:
    # check highest total value (in order): TaxableValueTotal, TaxableValueImprovements+TaxableValueLand, MarketValueTotal,
    #    MarketValueImprovements, MarketValueLand
    # check whether tabular acre even remotely close to POLY_AREA

#If other than single family:
    #Check if # in ProcessParcelFlattened+1 matches number of records




#Join taxroll attributes to parcel polygons (one-to-many relationship from parcel to taxrollIDs so require query
arcpy.MakeFeatureLayer_management(parcel, 'parcel_lyr')
try:
    SQLjoin = 'Parcel.PolyID = TaxRoll.PolyID'
    # Make Query Table...
    arcpy.MakeQueryTable_management([parcel, parcel_taxroll], 'parcel_taxroll_query', "ADD_VIRTUAL_KEY_FIELD", where_clause=SQLjoin)
except Exception as err:
    print(err.args[0])
arcpy.CopyFeatures_management('parcel_taxroll_query', 'parcel_taxroll')
import arcpy
import os
import sys
import re
import time
from collections import defaultdict

arcpy.CheckOutExtension("Spatial")
arcpy.env.overwriteOutput = True
arcpy.env.qualifiedFieldNames = False

#Folder structure
rootdir = 'C:/Mathis/ICSL/flood_vulnerability'
datadir = os.path.join(rootdir, 'data')
resdir = os.path.join(rootdir, 'results')
gdb_vulne = os.path.join(resdir,'flood_vulnerability.gdb')

gdb = os.path.join(resdir,'flood_risk.gdb')
if arcpy.Exists(gdb):
    print('Geodatabase already exists')
else:
    arcpy.CreateFileGDB_management(resdir, 'flood_risk.gdb')
arcpy.env.workspace = gdb

counties = os.path.join(datadir,"WA_County_Boundaries\WA_County_Boundaries.shp")

WAdb = os.path.join(datadir, 'WAParcel\StatewideParcels_v2012_e9.2_r1.3\StatewideParcels_v2012_e9.2_r1.3.gdb')#Washington statewide parcel database
parcel = os.path.join(WAdb, 'Land\Parcel')
parcel_name = os.path.join(WAdb, 'Name')
parcel_taxroll = os.path.join(WAdb, 'TaxRoll')
parcel_taxrollname_r = os.path.join(WAdb, 'TaxRollsHaveNames')
StateLU =  os.path.join(WAdb, 'StateLandUse')
provider = os.path.join(WAdb, 'DataProvider')

#Output variables
parcel_nogeodupli = 'parcel_o5county_nogeodupli'
taxroll_nogeodupli = 'taxroll_nogeodupli'

#Define functions
def selfintersect(feature, outfeature, IDfield) :
    #Create identical copy of dataset to intersect
    arcpy.CopyFeatures_management(feature, feature+'_2')
    #Self intersect parcel dataset to know what parcel overlaps which other one
    co_inters = feature+'_inters'
    arcpy.Intersect_analysis([feature, feature+'_2'], co_inters)
    #Only keep intersections resulting from overlap between two separate parcels
    arcpy.MakeFeatureLayer_management(co_inters, outfeature+'lyr', where_clause='NOT "{0}"="{0}_1"'.format(IDfield))
    arcpy.CopyFeatures_management(outfeature+'lyr',outfeature)
    arcpy.Delete_management(feature+'_2')

#Set initial variable
#Create list of data providers code
providerID = {}
for row in arcpy.da.SearchCursor(provider, ['DataProviderID','Name']):
    providerID[row[0]] = row[1]

#-----------------------------------------------------------------------------------------------------------------------
# CLEAN PARCEL DATASET
#-----------------------------------------------------------------------------------------------------------------------
#Remove parcels < 5m2 - cannot hold any housing, often slivers due to polygon processing
arcpy.AddGeometryAttributes_management(parcel, 'AREA', Area_Unit='SQUARE_METERS')
arcpy.MakeFeatureLayer_management(parcel, 'parcel_lyr', '"POLY_AREA">5')
arcpy.CopyFeatures_management('parcel_lyr', 'parcel_o5')

#Separate county data from other state and federal data
#DNR: 640, WDFW: 641, BLM: 843
arcpy.MakeFeatureLayer_management('parcel_o5', 'parcel_o5lyr', 'NOT "DataProviderID" IN {}'.format(str(tuple([640,641,843]))))
arcpy.CopyFeatures_management('parcel_o5lyr', 'parcel_o5county')

#Check for polygons with duplicate geometry
arcpy.FindIdentical_management('parcel_o5county', 'parcel_o5county_geodupli', fields='Shape', output_record_option='ONLY_DUPLICATES')
arcpy.MakeFeatureLayer_management('parcel_o5county', 'parcel_o5county_lyr')
arcpy.AddJoin_management('parcel_o5county_lyr', 'OBJECTID', 'parcel_o5county_geodupli', 'IN_FID', join_type='KEEP_COMMON')
arcpy.CopyFeatures_management('parcel_o5county_lyr', 'parcel_o5county_geoduplipoly')

arcpy.MakeTableView_management(parcel_taxroll, 'taxroll_view')
arcpy.AddJoin_management('taxroll_view','PolyID','parcel_o5county_geoduplipoly','PolyID', join_type='KEEP_COMMON')
arcpy.CopyRows_management('taxroll_view', 'taxroll_parcel_o5county_geoduplipoly')

#------------------------- Deal with exactly duplicate polygon geometries ------------------------------------------------------
#Check https://depts.washington.edu/wagis/projects/parcels/techdocs/ for more info on removing and flattening records
#Make copy of parcel_o5county
arcpy.CopyFeatures_management('parcel_o5county', parcel_nogeodupli)
#Add Field: ProcessParcelFlattened_MM
arcpy.AddField_management(parcel_nogeodupli , 'ProcessParcelFlattened_MM', field_type='SHORT')
arcpy.CalculateField_management(parcel_nogeodupli, 'ProcessParcelFlattened_MM',
                                expression='!ProcessParcelFlattened!', expression_type='PYTHON')
#Add Field: ProcessParcelDuplicatesRemoved_MM
arcpy.AddField_management(parcel_nogeodupli , 'ProcessParcelDuplicatesRemoved_MM', field_type='SHORT')
arcpy.CalculateField_management(parcel_nogeodupli, 'ProcessParcelDuplicatesRemoved_MM',
                                expression='!ProcessParcelDuplicatesRemoved!', expression_type='PYTHON')
#Prepare dics for removal and flattening
polyflatten = defaultdict(list)
polyremove = defaultdict(list)
polykeep = defaultdict(list)
#Define fields to check for identifying identical records
regx_fields = re.compile('|'.join(['PolyID.*', 'TaxRollID.*', 'TaxAccountID.*', 'SourceParcelID.*', 'OBJECTID.*',
                                   'IN_FID.*','POLY_AREA.*','SHAPE_Length.*','SHAPE_Area.*','ProcessParcelDuplicatesRemoved',
                                   'GISAcres']))
checkidentical_fields = [f.name for f in arcpy.ListFields('taxroll_parcel_o5county_geoduplipoly') if not regx_fields.search(f.name)]

duplipoly_fields = ['PolyID','FEAT_SEQ','ProcessParcelFlattened','ProcessParcelDuplicatesRemoved']
fieldlim = len(duplipoly_fields)
with arcpy.da.SearchCursor('taxroll_parcel_o5county_geoduplipoly', duplipoly_fields+checkidentical_fields) as cursor:
    for row in cursor:
        print(row)
        if row[1] not in polykeep: #If FEAT_SEQ not already in polykeep dic
            polykeep[row[1]] = list(row) #Add to polykeep
        else:
            if polykeep[row[1]][fieldlim:]==list(row[fieldlim:]): #If identical records in terms of attributes
                if polykeep[row[1]][0] != row[0]:
                    print('Identical!')
                    # Based on PolyID, add ProcessParcelDuplicatesRemoved + PolyID of the polygon to keep to polyremove dic
                    polyremove[row[0]]=[row[3],polykeep[row[1]][0]]
            else:
                if polykeep[row[1]][0] != row[0]: #If different PolyID
                    if polykeep[row[1]][2] <= row[2]:  #If ProcessParcelFlattened > that in dictionary
                        polyflatten[row[0]] = [polykeep[row[1]][2], row[0]]  #Add that in polykeep to polyflatten
                        polykeep[row[1]] = list(row) #Add current one to polyflatten
                    else:
                        polyflatten[row[0]]= [row[2],polykeep[row[1]][0]] #Add to polyflatten

#Delete duplicated polygons in parcel dataset
parcelclean_fields = ['PolyID','ProcessParcelFlattened_MM','ProcessParcelDuplicatesRemoved_MM']
with arcpy.da.UpdateCursor(parcel_nogeodupli, parcelclean_fields) as cursor:
    for row in cursor:
        try:
            #INCREMENTING FLATTEN COUNT
            if row[0] in [v[1] for v in polyflatten.values() if len(v) > 1]:  # if poly associated with a flattened polygon, increment ProcessParcelFlattened_MM
                print('Increment flatten count' + str(row[0]))
                flattencount_prior = [v[0] for v in polyflatten.values() if len(v) > 1 and row[0] == v[1]][0]
                if row[1] is None:
                    row[1] = 1
                if flattencount_prior is None:  # Add 1 if no previously flattened polygon
                    row[1] = row[1] + 1
                else:
                    row[1] = row[1] + flattencount_prior
                cursor.updateRow(row)
            #INCREMENTING REMOVAL COUNT
            if row[0] in [v[1] for v in polyremove.values() if len(v)>1]: #if poly associated with a removed polygon, increment ProcessParcelDuplicatesRemoved_MM
                print('Increment remove count' + str(row[0]))
                removecount_prior = [v[0] for v in polyremove.values() if len(v) > 1 and row[0] == v[1]][0]
                if row[2] is None:
                    row[2]=1
                if removecount_prior is None: #Add 1 if no removed polygons previously associated with deleted polygon
                    row[2]=row[2]+1
                else:
                    row[2]=row[2]+removecount_prior
                cursor.updateRow(row)
            #DELETE ROW IF IN REMOVE DIC
            if row[0] in polyremove or row[0] in polyflatten: #if PolyID in remove or flatten dictionary
                print('Delete'+str(row[0]))
                cursor.deleteRow() #Delete polygon
        except:
            print(row[0])
            e = sys.exc_info()[1]
            print(e.args[0])
del row
del cursor

#Edit Taxroll records to point taxroll to correct polygon (as some duplicated polygons were deleted)
arcpy.CopyRows_management(parcel_taxroll, taxroll_nogeodupli)
with arcpy.da.UpdateCursor(taxroll_nogeodupli, ['PolyID']) as cursor:
    print(row[0])
    if row[0] in polyflatten: #If row was deleted because identical poly geometry but different taxroll data, then
        row[0]=polyflatten[row[0]][1]  #Change PolyID in taxroll record to refer to the remaining (unique) polygon
        cursor.updateRow(row)
    if row[0] in polyremove: #If row was deleted because poly geometry and taxroll record was identical, then
        cursor.deleteRow() #Delete TaxRoll record as identical
del row
del cursor

#------------------------- Check and deal with other intersecting polygons ---------------------------------------------
#Get full parcel area before start of any intersection
arcpy.AlterField_management('parcel_o5county', 'POLY_AREA', 'PARCELAREA', 'PARCELAREA')
#Check whether polygon is multipart
arcpy.AddGeometryAttributes_management('parcel_o5county', 'PART_COUNT')

#For each county run through cleaning steps (but exclude Whitman county as no spatial parcel data).
#Whitman county: 438, DNR: 640, WDFW: 641, BLM: 843
for countycode in providerID.keys():
    if countycode not in [438, 640, 641, 843]:
        countyname = providerID[countycode].split()[0]
        tic = time.clock()
        print('Format county parcels for '+ providerID[countycode])
        #Subset county parcels
        arcpy.MakeFeatureLayer_management('parcel_o5county', 'parcel_o5{}_lyr'.format(countyname), where_clause='"DataProviderID"={}'.format(countycode))
        #Multipart to singlepart
        parcel_co = 'parcel_o5{}'.format(countyname)
        arcpy.MultipartToSinglepart_management('parcel_o5{}_lyr'.format(countyname), parcel_co)
        #Compute area of single part of parcel
        arcpy.AddGeometryAttributes_management(parcel_co, 'AREA', Area_Unit='SQUARE_METERS')
        arcpy.AlterField_management(parcel_co, 'POLY_AREA', 'PARTAREA', 'PARTAREA')

        #-------------------- 1. Deal with overlapping 'nearly' duplicate geometries ----------------------------------------------------
        print('Deal with overlapping duplicate geometries')
        co_sub1 = 'parcel_o5{}_interssub'.format(countyname)
        selfintersect(parcel_co, co_sub1, 'PolyID')

        #Check percentage overlap between polygons
        arcpy.AddGeometryAttributes_management(co_sub1, 'AREA', Area_Unit='SQUARE_METERS')
        arcpy.AddField_management(co_sub1, 'duplioverlap1', 'FLOAT')
        arcpy.AddField_management(co_sub1, 'duplioverlap2', 'FLOAT')
        arcpy.CalculateField_management(co_sub1, 'duplioverlap1', expression='!POLY_AREA!/!PARTAREA!', expression_type='PYTHON')
        arcpy.CalculateField_management(co_sub1, 'duplioverlap2', expression='!POLY_AREA!/!PARTAREA_1!', expression_type='PYTHON')

        #Make a dictionary of all duplicate polygons to remove
        duplidel = []
        with arcpy.da.SearchCursor(co_sub1, ['FID_parcel_o5{}'.format(countyname),'PARTAREA','PARTAREA_1','PolyID_1',
                                             'duplioverlap1','duplioverlap2','FID_parcel_o5{}_2'.format(countyname)]) as cursor:
            for row in cursor:
                if row[4]>0.85 and row[5]>0.85: #If at least 85% reciprocal overlap
                    if row[1] < row[2]: #Keep the largest one (works even if more than 2 polygons overlap)
                        duplidel.append(row[0])
                    if row[1] == row[2] and row[6] not in duplidel:
                        duplidel.append(row[0])
        if len(duplidel)>0:
            sql='NOT "OBJECTID" IN {}'.format(str(tuple(duplidel)))
            arcpy.MakeFeatureLayer_management(parcel_co, parcel_co+'_lyr', sql)
        else:
            arcpy.MakeFeatureLayer_management(parcel_co, parcel_co + '_lyr')
        arcpy.CopyFeatures_management(parcel_co+'_lyr', 'parcel_o5{}_clean1'.format(countyname))
        #To do: Add to parcel aggregate county

        #-------------------- 2.  Deal with enveloped polygons ----------------------------------------------------------------
        print('Deal with enveloped polygons')
        co_sub2 = 'parcel_o5{}_interssub2'.format(countyname)
        selfintersect('parcel_o5{}_clean1'.format(countyname), co_sub2, 'PolyID')
        #Multipart to singlepart
        arcpy.MultipartToSinglepart_management('parcel_o5{}_clean1_inters'.format(countyname), 'parcel_o5{}_clean1_inters2'.format(countyname))
        clean1inters = 'parcel_o5{}_clean1_inters2'.format(countyname)
        #Compute polygon thinness (https://tereshenkov.wordpress.com/2014/04/08/fighting-sliver-polygons-in-arcgis-thinness-ratio/)
        arcpy.AddField_management(clean1inters, 'thinness', 'float')
        arcpy.CalculateField_management(clean1inters, 'thinness',
                                        expression='4*3.14*!Shape_Area!/(!Shape_Length!*!Shape_Length!)',expression_type='PYTHON')
        arcpy.AddGeometryAttributes_management(clean1inters, 'AREA', Area_Unit='SQUARE_METERS')

        #Find groups of identical shapes
        identicaltab = clean1inters+'_identicaltab'
        arcpy.FindIdentical_management(clean1inters, identicaltab, fields='Shape',
                                       output_record_option='ONLY_DUPLICATES')
        arcpy.MakeFeatureLayer_management(clean1inters, clean1inters+'_lyr')
        arcpy.AddJoin_management(clean1inters+'_lyr', 'OBJECTID', identicaltab,'IN_FID', 'KEEP_ALL')
        co_clean2 = 'parcel_o5{}_clean2'.format(countyname)
        arcpy.CopyFeatures_management(clean1inters+'_lyr', co_clean2)

        #For each remaining overlapping polygon intersections, keep the part that belongs to the smallest parcel so that
        #envelopped parcels are kept and enveloping parcels are hollowed in that area.
        keepdic = defaultdict(list)
        with arcpy.da.SearchCursor(co_clean2,['FEAT_SEQ','OBJECTID','PARTAREA']) as cursor:
            for row in cursor:
                if row[0] is not None:
                    if row[0] not in keepdic:
                        keepdic[row[0]] = row[1:] #Add unique ID and parcel part area to dictionary
                    else:
                        if keepdic[row[0]][1] > row[2]:  #Keep smallest original parcel part
                            keepdic[row[0]] = row[1:]
        keeplist = [v[0] for v in keepdic.values()]

        #Delete rest of overlapping intersections not in keeplist
        with arcpy.da.UpdateCursor(co_clean2, ['FEAT_SEQ','OBJECTID']) as cursor:
            for row in cursor:
                if row[0] is not None:
                    if row[1] not in keeplist:
                        cursor.deleteRow()

        #-------------------- 3.  Deal with slivers ----------------------------------------------------------------
        print('Deal with slivers')
        #Dissolve small slivers within adjacent polygon that shares the longest boundary with it
        sliver_sql = '("thinness" <= 0.1 AND "POLY_AREA" <= 200) OR "POLY_AREA" <= 5 OR "thinness" <= 0.05'
        arcpy.MakeFeatureLayer_management(co_clean2, co_clean2+'_lyr')
        arcpy.SelectLayerByAttribute_management(co_clean2+'_lyr', 'NEW_SELECTION',sliver_sql)
        co_clean3 = 'parcel_o5{}_clean3'.format(countyname)
        arcpy.Eliminate_management(co_clean2+'_lyr', co_clean3,selection="LENGTH")
        #A lot of slivers are left, surely due to equal length of shared boundary, so do it based on area
        arcpy.MakeFeatureLayer_management(co_clean3, co_clean3+'_lyr')
        arcpy.SelectLayerByAttribute_management(co_clean3+'_lyr', 'NEW_SELECTION', sliver_sql)
        arcpy.Eliminate_management(co_clean3+'_lyr', co_clean3+'b',selection="AREA")
        #Some slivers are still left: delete remaining sliver polygons and adjust polygon boundaries to fill the gaps
        arcpy.MakeFeatureLayer_management(co_clean3+'b', co_clean3+'b_lyr')
        arcpy.SelectLayerByAttribute_management(co_clean3+'b_lyr', 'NEW_SELECTION', sliver_sql)
        arcpy.DeleteFeatures_management(co_clean3+'b_lyr')
        arcpy.CopyFeatures_management(co_clean3+'b_lyr', co_clean3+'c')
        arcpy.Integrate_management(co_clean3, cluster_tolerance='0.50 meters')

        co_sub3 = 'parcel_o5{}_interssub3'.format(countyname)
        selfintersect(co_clean3+'c', co_sub3, 'PolyID')

        #Dissolve by PolyID creating multiparts
        print('Dissolve parcels back together')
        co_clean3diss = co_clean3+'_dissolve'
        arcpy.Dissolve_management(co_clean3+'c', co_clean3diss, dissolve_field='PolyID', multi_part='MULTI_PART')

        toc = time.clock()
        print(toc-tic)

#-------------------- 4. Deal with overlap between counties ------------------------------------------------------



#Spatial join with WA counties to know which parcels are completely within a county and which
co_join = co_sub+'_join'
arcpy.SpatialJoin_analysis(co_sub, counties, co_join, join_operation='JOIN_ONE_TO_ONE', match_option='COMPLETELY_WITHIN')
#Self intersect parcel dataset to know what parcel overlaps which other one
co_inters = 'parcel_o5columbia_inters'
arcpy.Intersect_analysis(['parcel_o5columbia', 'parcel_o5county'], co_inters)
#Only keep intersections resulting from overlap between two separate parcels
[f.name for f in arcpy.ListFields(co_inters)]
co_sub = co_inters+'sub'
arcpy.MakeFeatureLayer_management(co_inters, co_sub+'lyr', where_clause='NOT "PolyID"="PolyID_1"')
arcpy.CopyFeatures_management(co_sub+'lyr',co_sub)
# if polygon is fully contained within a county, then erase overlap from polygon of other county
#   Otherwise, eliminate overlapping area simply based on drawing order

#Run through parcel_o5columbia_interssub_join
# If JURISDIC_2 is not NULL:
    #if DataProviderID != JURISDIC_2:
        #Add PolyID to dic
        #
    #if DataProviderID_1 != JURISDIC_2:
        #Add PolyID_1 to dic
















#5. For big messes like Whitman County: just create a uniform layer trying to keep the largest polygons.





"""Observed patterns of parcel overlaps:
1. Slivers created along edges of polygons. Not a problem. Can delete overlap if small. 
2. Whitman County overall is a mess, all polygons are overlapping in potentially meaningless ways. 
Not sure that it is usable?
3. Multiple polygons are embedded within a larger one (e.g. paper product factor within a lumber yard, individual
mobile homes within a mobile home park). Can identify those polygons fully contained within another and erasing enveloping
polygon from the smaller polygon's footprint. 
4. Duplicate polygons over county boundaries. In this case, 
5. A a lot of duplicate geometries still where two polygons are visibly identical and fully overlap, yet not 100% so were
not identified by FindIdentical on !SHAPE!. Is there a need to relax the tolerance of the Find Identical tool? 
    - Test multiple tolerance threshold in FindIdentical on an area with a lot of overlapping duplicates of Columbia County: 
    Try 1,2, 5, 10, 25 m. Even at 25 m, still not great. Not going to work.
    - Identify those polygons that overlap for more than 99% of each other's surface area? See how that goes. Otherwise,
    can try a centroid+perimeter+area check.  
"""


##################INSPECT DUPLICATE POLYID IN TAXROLL############
#Often, when a parcel contains multiple sub-properties (e.g. condo building contains multiple condos), then a single
#POLYID (parcel) may be associated with multiple TaxRollID (units that could be paid taxes one).
#However, there can't be several NameID per TaxRollID and some duplicate POLYID are erroneous

# Check for ProcessParcelFlattened

#Check which of:
    #TabularAcre of each individual record or sum of all records best matches polygon area
#If no tabular acres and single family:
    # check highest total value (in order): TaxableValueTotal, TaxableValueImprovements+TaxableValueLand, MarketValueTotal,
    #    MarketValueImprovements, MarketValueLand
    # check whether tabular acre even remotely close to POLY_AREA

#If other than single family:
    #Check if # in ProcessParcelFlattened+1 matches number of records




#Join taxroll attributes to parcel polygons (one-to-many relationship from parcel to taxrollIDs so require query
arcpy.MakeFeatureLayer_management(parcel, 'parcel_lyr')
try:
    SQLjoin = 'Parcel.PolyID = TaxRoll.PolyID'
    # Make Query Table...
    arcpy.MakeQueryTable_management([parcel, parcel_taxroll], 'parcel_taxroll_query', "ADD_VIRTUAL_KEY_FIELD", where_clause=SQLjoin)
except Exception as err:
    print(err.args[0])
arcpy.CopyFeatures_management('parcel_taxroll_query', 'parcel_taxroll')